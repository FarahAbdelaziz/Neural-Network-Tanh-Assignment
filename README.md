This project implements a simple forward pass of a neural network with:

- 2 input neurons  
- 2 hidden neurons  
- 2 output neurons  

Specifications:
- Activation function: tanh  
- Weights initialized randomly in range [-0.5, 0.5]  
- b1 = 0.5  
- b2 = 0.7
  
 How to run
python tanh_network.py

The program prints:
- Input values 
- Hidden layer output  
- Final output

